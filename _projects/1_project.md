---
layout: page
title: mwTokenizer
description: Python library for multilingual tokenization
img: assets/img/12.jpg
importance: 1
category: research
github: https://gitlab.wikimedia.org/repos/research/wiki-nlp-tools
# related_publications: einstein1956investigations, einstein1950meaning
---

Python package to perform language-agnostic tokenization. Researchers can start with a Wikipedia article (wikitext or HTML), strip syntax to leave just paragraphs of plaintext, and then further tokenize these sentences into sentences and words for input into models. <a href='https://pypi.org/project/mwtokenizer/'> <b>Install from PyPI</b></a>

Tags: 
    ---
    Python
    Regex
    Tokenization
    Benchmarking
    ---
